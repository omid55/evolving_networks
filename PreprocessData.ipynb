{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preprocess Dynamic Network Data and Build Small Temporal Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Omid55\n",
    "# all imports\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix\n",
    "import warnings\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data from text edges list (sparse representation of edges)\n",
    "# output =>\n",
    "# input  =>\n",
    "# fname: \n",
    "# ...\n",
    "def load_data(fname, delim, skip_rows_count):\n",
    "    edges = np.loadtxt(open(fname,\"rb\"),delimiter=delim,skiprows=skip_rows_count)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "# ...\n",
    "def build_unconstrained_network(subset_of_edges, N):\n",
    "    data = np.ones(len(subset_of_edges))\n",
    "    row = np.subtract(subset_of_edges[:,0],1)\n",
    "    col = np.subtract(subset_of_edges[:,1],1)\n",
    "    A = csr_matrix((data,(row,col)), shape=(N,N))\n",
    "    #D = A.todense()\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# process the edges list created from load_data and build evolving networks\n",
    "# output =>  array of adjacency matrixes\n",
    "# inputs =>\n",
    "# edges:         edges list\n",
    "# window_size:   window size in time or in number of edges\n",
    "# step_size:     step size in time or in number of edges\n",
    "# edges_as_unit:      window size in number of edges or in time\n",
    "def process_data(edges, window_size, step_size, edges_as_unit=True):\n",
    "    if(window_size < step_size):\n",
    "        warnings.warn(\"You are wasting some data points. To fix that, window_size should be >= step_size.\", \n",
    "                      UserWarning)\n",
    "    N = int(max(edges[:,0].max(), edges[:,1].max()))      # nodes count\n",
    "    E = len(edges)        \n",
    "    \n",
    "    if(edges_as_unit):\n",
    "        # in number of edges:                             # edges count\n",
    "        total = E\n",
    "        \n",
    "        n = math.floor((total - window_size) / step_size) + 1              # the number of chunks that will be created\n",
    "        print(\"Info=>   Nodes:\", N, \"  Edges:\", E, \"  Networks:\", n, \"  WindowSize:\", window_size, \"  StepSize:\",\n",
    "              step_size, \"  SamplesLeftOff:\", E - window_size - (n-1)*step_size)\n",
    "        As = dict.fromkeys(set(range(n)))\n",
    "\n",
    "        for i in range(0,n):\n",
    "            subset_of_edges = edges[i * step_size: i * step_size + window_size];\n",
    "            As[i] = build_unconstrained_network(subset_of_edges, N)\n",
    "        return As\n",
    "    else:\n",
    "        # in time\n",
    "        start_time = edges[0,2]\n",
    "        end_time = edges[-1,2]\n",
    "        total = end_time - start_time + 1\n",
    "        \n",
    "        n = math.floor((total - window_size) / step_size) + 1       # the number of chunks that will be created\n",
    "        print(\"Info=>   Nodes:\", N, \"  Edges:\", E, \"  Networks:\", n, \"  WindowSize:\", window_size, \"  StepSize:\",\n",
    "               step_size, \"  TimeLeftOff:\", total - window_size - (n-1)*step_size, \n",
    "              \"  SamplesLeftOff:\", np.where(edges[:,2] > start_time + window_size + (n-1)*step_size)[0].size)\n",
    "        As = dict.fromkeys(set(range(n)))\n",
    "\n",
    "        for i in range(0,n):\n",
    "            a = start_time + i * step_size\n",
    "            b = a + window_size\n",
    "            indices = np.where(abs(edges[:,2]-(a+b)/2) <= (b-a)/2)\n",
    "            subset_of_edges = edges[indices]\n",
    "            As[i] = build_unconstrained_network(subset_of_edges, N)\n",
    "        return As"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info=>   Nodes: 899   Edges: 33720   Networks: 981   WindowSize: 86400   StepSize: 14400   TimeLeftOff: 13706.0   SamplesLeftOff: 2\n"
     ]
    }
   ],
   "source": [
    "# -- test dataset --\n",
    "#e = load_data(\"test.txt\", ',', 0)\n",
    "#As = process_data(e, 5, 2)\n",
    "#As = process_data(e, 50, 5, edges_as_unit=False)\n",
    "\n",
    "e = load_data(\"fb-forum.txt\", ',', 0)\n",
    "#As = process_data(e, 200, 40)\n",
    "As = process_data(e, 24*3600, 4*3600, edges_as_unit=False)\n",
    "\n",
    "#e = load_data('dblp_coauthor/out.dblp_coauthor', ' ', 1, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute eigen values, shortest paths, centrality measures and so forth and store them in a sorted order\n",
    "#        and the other dimension should be time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
